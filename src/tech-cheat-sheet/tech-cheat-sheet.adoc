:toc: left
:toclevels: 4
= Technical Cheat Sheet

A dumping ground for commands I've collected at random over the years. I really need to go through this and clean it up in due course.

== Docker

=== Export / Import Docker container
```bash
# Export the image to a tar file
docker save -o <path for generated tar file> <image name>

# Import it where you need it
docker load -i <path to image tar file>
```

=== How to use a docker container when specific version of kubectl is required
```bash
docker run --entrypoint ["tail", "-f", "/dev/null"] --name kubectl116 -v /home/user/<username>/.kube/config:/.kube/config bitnami/kubectl:1.16
```

=== Run containers
```bash
# One off busybox
docker run -it --rm busybox
```

=== Start up Racher Server in Dev environment
```bash
sudo docker volume create \
  -d netapp \ # If using NetApp driver
  --name rancherData --opt size=20G

sudo docker run -d --restart=unless-stopped \
  -p 80:80 -p 443:443 \
  -v rancherData:/var/lib/rancher \
  --privileged \
  --name=rancher \
  rancher/rancher:latest
```

== Kubernetes

=== Basics
```bash
# List all resources in a namespace
kubectl -n default api-resources --namespaced=true -o name | xargs --verbose -I {} kubectl -n NAMESPACE get {} --show-kind --ignore-not-found

# List all resources in all namespaces
kubectl -n default api-resources --namespaced=true -o name | xargs --verbose -I {} kubectl -n NAMESPACE get {} --show-kind --ignore-not-found

for n in $(kubectl get namespaces -o jsonpath={..metadata.name}); do
  kubectl -n $n api-resources --namespaced=true -o name | xargs --verbose -I {} kubectl -n $n get {} --show-kind --ignore-not-found >> tmp.log
done

# List all nodes in the cluster
kubectl get nodes

# List all the pods in all namespaces
kubectl get pods --all-namespaces

# List all the namespaces in the cluster
kubectl get namespaces

# Check to see if there are any pods running in the default namespace
kubectl get pods
kubectl get pods -n default

# Find the IP address of the API server running on the master node
kubectl get pods --all-namespaces -o wide

# Find deployments in the cluster
kubectl get deployments --all-namespaces

# Find pod labels
kubectl get pods --all-namespaces --show-labels -o wide

# Helpful bash autocomplete stuff
yum install -y bash-completion
source <(kubectl completion bash) # setup autocomplete in bash into the current shell, bash-completion package should be installed first.
echo "source <(kubectl completion bash)" >> ~/.bashrc # add autocomplete permanently to your bash shell.
alias k=kubectl
complete -F __start_kubectl k

# Port forward app1 with screen
screen -dmS app1 kubectl -n <namespace> port-forward deployment/app1 8081:8081 --address=0.0.0.0

# Example of a custom column output
kubectl get pods -o custom-columns=POD:metadata.name,NODE:spec.nodeName --sort-by spec.nodeName -n kube-system

# Manually execute a cronjob (creates a new job so remember to clean up after if desirable)
kubectl create job --from=cronjob/<cronjob-name> <job-name>
kubectl delete job <job-name>

# Kubectl cheat sheet links
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#kubectl-autocomplete
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#kubectl-context-and-configuration
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#creating-objects
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#viewing-finding-resources
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#updating-resources
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#patching-resources
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#editing-resources
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#scaling-resources
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#deleting-resources
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#interacting-with-running-pods
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#interacting-with-nodes-and-cluster
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#formatting-output
https://kubernetes.io/docs/reference/kubectl/cheatsheet/#kubectl-output-verbosity-and-debugging

# Change default namespace to 'demo'
kubectl config set-context --current --namespace=demo

# List all the APIs in a cluster
kubectl api-resources -o name

# Liveness versus Readiness
Liveness is a custom way to check if the pod is healthy, and if not to restart the pod. If the liveness probe fails, the pod is restarted.
Readiness means the pod is ready to service requests (it will be added as a live endpoint).

# Script to find all PV's with a status != 'Bound' and delete them
kubectl -n <namespace> get pv | tail -n +2 | grep -v Bound | awk '{print $1}' | xargs -I{} kubectl -n <namespace> delete pv {}

# Add the following feature-gate setting to /etc/kuberenetes/manifests/kube-apiserver.yaml to enable alpha snap shot features on master nodes.
# - --feature-gates=VolumeSnapshotDataSource=true

# This kubectl command selects all Pods for which the value of the status.phase field is Running:
kubectl get pods --field-selector status.phase=Running

# These in effect mean the same:
kubectl get pods
kubectl get pods --field-selector ""

# Chaining queries
kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always
kubectl get statefulsets,services --all-namespaces --field-selector metadata.namespace!=default
```

=== Changing environment variables
```bash
# Add or edit an environment variable 'TEST'
kubectl -n <namespace> set env deployment/<deployment> --containers=<container> TEST="123"

# Remove the environment variable 'TEST'
kubectl -n <namespace> set env deployment/<deployment> --containers=<container> TEST-

# Show all environment variables
kubectl -n <namespace> set env deployment/<deployment> --list
```

=== Changing images
```bash
# Get all pod images
kubectl get pods --all-namespaces -o=jsonpath='{range .items[*]}{"\n"}{.metadata.name}{":\t"}{range .spec.containers[*]}{.image}{", "}{end}{end}' |\
sort

# Update container image
kubectl -n <namespace> set image deployment/<deployment-name> <container-name>=<container:tag> --record
 
# Undo deployment
kubectl -n <namespace> rollout undo deployment/<deployment-name>

```

=== Deployment rollouts with kubectl
```bash
## Create and roll out a deployment, and verify the deployment was successful.
cat << EOF > kubeserv.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubeserve
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kubeserve
  template:
    metadata:
      name: kubeserve
      labels:
        app: kubeserve
    spec:
      containers:
      - image: linuxacademycontent/kubeserve:v1
        name: app
EOF

kubectl apply -f kubeserve-deployment.yaml --record

kubectl rollout status deployment kubeserve

## Verify the application is using the correct version.
kubectl describe deployment kubeserve

## Scale up your application up to 10 pods to create high availability
kubectl scale deployment kubeserve --replicas 10

## Create a service from your deployment, so users can access your application.
kubectl expose deployment kubeserve --port=80 --target-port=80 --type NodePort
kubectl get service

## Perform a rolling update to version 2 of the application.
kubectl set image deployments/kubeserve app=linuxacademycontent/kubeserve:v2 --v 6

## Verify the app is now at version 2 and there was no downtime to end users.
kubectl rollout history deployment kubeserve
```
=== Example of restricting a pod to a specific K8s resource
```bash
#    View the Persistent Volume using the kubectl command line tool.
kubectl get pv
kubectl describe pv

# Create a ClusterRole.
kubectl create clusterrole pv-reader --verb=get,list --resource=persistentvolumes

# Create a ClusterRoleBinding.
kubectl create clusterrolebinding pv-test --clusterrole=pv-reader --serviceaccount=web:default

# Create a pod within the namespace 'web' to access the PV.
cat << EOF > curlpod.yml
apiVersion: v1
kind: Pod
metadata:
  name: curlpod
  namespace: web
spec:
  containers:
  - image: tutum/curl
    command: ["sleep", "9999999"]
    name: main
  - image: linuxacademycontent/kubectl-proxy
    name: proxy
  restartPolicy: Always
EOF
kubectl apply -f curlpod.yml

# Request access to the PV from the pod.
kubectl exec -it curlpod -n web -- sh
curl localhost:8001/api/v1/persistentvolumes
```

=== NGINX load balancer for Kube API
```bash
# Install NGINX
sudo apt-get install -y nginx
sudo systemctl enable nginx

# Configure Nginx to balance Kubernetes API traffic across the two controllers.
# Do the following to configure the Nginx load balancer:
sudo mkdir -p /etc/nginx/tcpconf.d
sudo vi /etc/nginx/nginx.conf

# Add the following configuration at the bottom of nginx.conf:
include /etc/nginx/tcpconf.d/*;

# Create a config file to configure Kubernetes API load balancing:
cat << EOF | sudo tee /etc/nginx/tcpconf.d/kubernetes.conf
stream {
    upstream kubernetes {
        server <k8m01-ip>:6443;
        server <k8m02-ip>:6443;
        server <k8m03-ip>:6443;
    }

    server {
        listen 6443;
        listen 443;
        proxy_pass kubernetes;
    }
}

EOF

# Reload the Nginx configuration:
sudo nginx -s reload

# You can verify that everything is working by making a request to the Kubernetes API through the load balancer:
curl -k https://localhost:6443/version
```

=== Pause a workload
```bash
image: <container-image:tag>
command: ["tail", "-f", "/dev/null"]
```

=== Prometheus fixes
```bash
# I'm sure this would have been patched by now but remember needing to do this at some point in the earlier days of the Prometheus Operator.
# Ensure ETCD is listening on all interfaces by editing the manifest on the master nodes
# SSH to each master node and edit the following line in /etc/kubernetes/manifests/etcd.yaml
# OLD:- --listen-metrics-urls=http://127.0.0.1:2381
# NEW:- --listen-metrics-urls=http://0.0.0.0:2381
# Then, edit the prom-kube-etcd service in the kube-system namespace to ensure the correct port is being used
kubectl edit service -n kube-system prom-kube-etcd
# update the 'targetPort' from 2379 to 2381

# Edit the kube-proxy configmap to listen on all interfaces.
kubectl edit configmap -n kube-system kube-proxy
# update the 'metricsBindAddress' from '127.0.0.1:10249' to '0.0.0.0:10249'
# A manual restart of the Kube Proxy daemon set is required to apply the changes
kubectl rollout restart daemonset -n kube-system kube-proxy
```

=== Replace a master node with kubeadm
```bash
# From https://octetz.com/docs/2019/2019-03-26-ha-control-plane-kubeadm/.
# Maybe deprecated by now, need to check.

# Run kubeadm reset on broken master
sudo kubeadm reset

# Delete node with kubectl
kubectl delete node <master>

# On healthy Master
sudo kubeadm token create --ttl 1h --print-join-command
sudo kubeadm init phase upload-certs --experimental-upload-certs

# On new/replaced Master, use the outputs from above
sudo kubeadm join <kubeapi address> \
    --control-plane \
    --certificate-key <cert-key> \
    --token <token> \
    --discovery-token-ca-cert-hash <ca-cert-hash>
```

=== Resource testing
```bash
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: resource-consumer-big
spec:
  containers:
  - name: resource-consumer
    image: gcr.io/kubernetes-e2e-test-images/resource-consumer:1.4
    resources:
      requests:
        cpu: 500m
        memory: 128Mi
  - name: busybox-sidecar
    image: radial/busyboxplus:curl
    command: [/bin/sh, -c, 'until curl localhost:8080/ConsumeCPU -d "millicores=300&durationSec=3600"; do sleep 5; done && sleep 3700']
EOF

kubectl top pods
kubectl top pod resource-consumer-big
kubectl top pods -n kube-system
kubectl top nodes
```
=== Tcpdump pod as sidecar
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: example

spec:
  containers:
  - name: tcpdump
    image: corfr/tcpdump
    command: 
    - /bin/sleep
    - infinity
  - name: nginx
    image: nginx:latest
  restartPolicy: Never
  dnsConfig:
    options:
    - name: ndots
      value: "1"
```
=== Using local storage
```bash
# Create a folder to use on worker node 'k8w01'
mkdir -p /home/app/datavol
```
```yaml
# Create a persistent volume that uses the local storage
apiVersion: v1
kind: PersistentVolume
metadata:
  name: datavol
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: local-storage
  local:
    path: /home/app/datavol/
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - k8w01
```

=== Utility pods with kubectl run
```bash
# DNS
kubectl run -it -n kube-system --rm --image=gcr.io/kubernetes-e2e-test-images/dnsutils:1.3 --restart=Never dnsutils -- nslookup kubernetes.default

# MySQL
kubectl run -it --rm --image=mysql:5.7 --restart=Never mysql-client -- mysql -u <username> -h <mysql-service> -p

# PostGres
kubectl run -it --rm --image=jbergknoff/postgresql-client --env="PGPASSWORD=password" --restart=Never psql -- psql --host=<posgres-service> --dbname=postgres --username postgres

# curl
kubectl run -it --rm --image=curlimages/curl --restart=Never curl -- curl http://<url> --max-time 5

# wget
kubectl run -it --rm --image=busybox --restart=Never busybox -- wget --spider http://<url> --max-time 5
```


== Linux

=== CentOS
==== Add VLAN to network interface
```bash
# Add VLAN tag to network interface
sudo su -
modprobe --first-time 8021q

# Variables
export VLANID=1055              # VLAN ID
export NETINT=ens192            # Network Interface
export IP=192.168.1.10          # IP Address
export SUB=24                   # Subnet Prefix
export NETID=192.168.1.0        # Network ID

# Create files
cat << EOF > /etc/sysconfig/network-scripts/ifcfg-$NETINT
DEVICE=$NETINT
TYPE=Ethernet
BOOTPROTO=none
ONBOOT=yes
EOF

cat << EOF > /etc/sysconfig/network-scripts/ifcfg-$NETINT.$VLANID
DEVICE=$NETINT.$VLANID
BOOTPROTO=none
ONBOOT=yes
IPADDR=$IP
PREFIX=$SUB
NETWORK=$NETID
VLAN=yes
EOF
```

==== Basic commands

```bash
# Create User Account
adduser username

# Specify password
passwd password

# Add user account to wheel, to allow sudo access
usermod -aG wheel username

# View HBA and Driver info
cat /proc/scsi/qla2xxx/0

# Display permissions
ls -lt

# Change permissions
chmod a+wr <filename>

# Firewall Commands
sudo systemctl stop firewalld
sudo systemctl start firewalld
sudo systemctl enable firewalld
sudo systemctl status firewalld

# Delete folder and everything under it - careful!
rm -rf .git

# Show Storage Information
blkid
lsblk

# See memory usage
free -h
```
==== Grow a file system
```bash
First, extend the vmdk by whatever size. In this example, we resized from 15GB to 60GB.
 
# Need to either reboot VM or run:
 
echo 1 > /sys/block/sda/device/rescan
 
#
# Once rebooted, confirm that /dev/sda is 60GB…
#
[root@server ~]# cat /proc/partitions
major minor  #blocks  name
 
   8        0   62914560 sda ß--------------------- now 60GB
   8        1    1048576 sda1
   8        2   15727616 sda2
  11        0    1048575 sr0
253        0   14045184 dm-0
253        1    1679360 dm-1
[root@server ~]# 
 
#
# You then need to resize the /dev/sda2 partition by deleting it and recreating it in fdisk. The data will remain intact just don't screw it up!
# 
[root@server ~]# fdisk /dev/sda
Welcome to fdisk (util-linux 2.23.2).
 
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.
 
 
Command (m for help): p
 
Disk /dev/sda: 64.4 GB, 64424509440 bytes, 125829120 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x00038d8d
 
   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *        2048     2099199     1048576   83  Linux
/dev/sda2         2099200    33554431    15727616   8e  Linux LVM ß----- paritition to grow from 15GB to 60GB
 
Command (m for help): d
Partition number (1,2, default 2): d
Partition number (1,2, default 2): 2
Partition 2 is deleted
 
Command (m for help): n
Partition type:
   p   primary (1 primary, 0 extended, 3 free)
   e   extended
Select (default p): p
Partition number (2-4, default 2): 2
First sector (2099200-125829119, default 2099200): 2099200
Last sector, +sectors or +size{K,M,G} (2099200-125829119, default 125829119): 125829119
Partition 2 of type Linux and of size 59 GiB is set
 
Command (m for help): t
Partition number (1,2, default 2): 2
Hex code (type L to list all codes): 8e
Changed type of partition 'Linux' to 'Linux LVM'
 
Command (m for help): p
 
Disk /dev/sda: 64.4 GB, 64424509440 bytes, 125829120 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x00038d8d
 
   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *        2048     2099199     1048576   83  Linux
/dev/sda2         2099200   125829119    61864960   8e  Linux LVM ß----- now 60GB. don’t forget to set Type of 8e
 
Command (m for help): w
The partition table has been altered!
 
Calling ioctl() to re-read partition table.
 
WARNING: Re-reading the partition table failed with error 16: Device or resource busy.
The kernel still uses the old table. The new table will be used at
the next reboot or after you run partprobe(8) or kpartx(8)
Syncing disks.
[root@server ~]# partprobe -s
/dev/sda: msdos partitions 1 2
[root@server ~]#
 
# Now the partition should be 60GB, but you now have to resize the LVM PV..
 
 
[root@server ~]#
[root@server ~]#
[root@server ~]# pvdisplay
  --- Physical volume ---
  PV Name               /dev/sda2
  VG Name               centos
  PV Size               <15.00 GiB / not usable 2.00 MiB
  Allocatable           yes (but full)
  PE Size               4.00 MiB
  Total PE              3839
  Free PE               0
  Allocated PE          3839
  PV UUID               XjhoR5-QBdj-ZTQw-5bd6-4dCt-vE2R-lj6e6y
 
[root@server ~]# pvresize /dev/sda2
  Physical volume "/dev/sda2" changed
  1 physical volume(s) resized or updated / 0 physical volume(s) not resized
[root@server ~]# pvdisplay
  --- Physical volume ---
  PV Name               /dev/sda2
  VG Name               centos
  PV Size               <59.00 GiB / not usable 2.00 MiB
  Allocatable           yes
  PE Size               4.00 MiB
  Total PE              15103
  Free PE               11264
  Allocated PE          3839
  PV UUID               XjhoR5-QBdj-ZTQw-5bd6-4dCt-vE2R-lj6e6y
 
# PV now resized. I once had to stop Docker service to get it to resize… something to look out for.
 
[root@server ~]# vgdisplay
  --- Volume group ---
  VG Name               centos
  System ID
  Format                lvm2
  Metadata Areas        1
  Metadata Sequence No  6
  VG Access             read/write
  VG Status             resizable
  MAX LV                0
  Cur LV                2
  Open LV               2
  Max PV                0
  Cur PV                1
  Act PV                1
  VG Size               <59.00 GiB
  PE Size               4.00 MiB
  Total PE              15103
  Alloc PE / Size       3839 / <15.00 GiB
  Free  PE / Size       11264 / 44.00 GiB
  VG UUID               HHtfVk-nLvn-lUbo-uXU9-2h8V-IcN6-dqKD0Z
 
[root@server ~]# lvdisplay
  --- Logical volume ---
  LV Path                /dev/centos/swap
  LV Name                swap
  VG Name                centos
  LV UUID                qzvWad-rsGy-lpSe-6DZ2-S44k-Vr6y-NE6c1a
  LV Write Access        read/write
  LV Creation host, time localhost, 2019-10-10 08:53:32 +1100
  LV Status              available
  # open                 2
  LV Size                1.60 GiB
  Current LE             410
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:1
 
  --- Logical volume ---
  LV Path                /dev/centos/root
  LV Name                root
  VG Name                centos
  LV UUID                lLGFJQ-Xx7r-HKco-GKIr-Myxw-0G6J-dAbxih
  LV Write Access        read/write
  LV Creation host, time localhost, 2019-10-10 08:53:34 +1100
  LV Status              available
  # open                 1
  LV Size                13.39 GiB
  Current LE             3429
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:0
 
# Now grow the LVM LV by adding 44GB (which is all that is available in VG)… resulting LV will be ~60GB (16+44GB).
 
[root@server ~]# lvextend -L +44G /dev/centos/root
  Size of logical volume centos/root changed from 13.39 GiB (3429 extents) to 57.39 GiB (14693 extents).
  Logical volume centos/root successfully resized.
[root@server ~]# lvdisplay
  --- Logical volume ---
  LV Path                /dev/centos/swap
  LV Name                swap
  VG Name                centos
  LV UUID                qzvWad-rsGy-lpSe-6DZ2-S44k-Vr6y-NE6c1a
  LV Write Access        read/write
  LV Creation host, time localhost, 2019-10-10 08:53:32 +1100
  LV Status              available
  # open                 2
  LV Size                1.60 GiB
  Current LE             410
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:1
 
  --- Logical volume ---
  LV Path                /dev/centos/root
  LV Name                root
  VG Name                centos
  LV UUID                lLGFJQ-Xx7r-HKco-GKIr-Myxw-0G6J-dAbxih
  LV Write Access        read/write
  LV Creation host, time localhost, 2019-10-10 08:53:34 +1100
  LV Status              available
  # open                 1
  LV Size                57.39 GiB
  Current LE             14693
  Segments               1
  Allocation             inherit
  Read ahead sectors     auto
  - currently set to     8192
  Block device           253:0
 
# Now grow the XFS filesystem
 
[root@server ~]# df -h /
Filesystem               Size  Used Avail Use% Mounted on
/dev/mapper/centos-root   14G  3.1G   11G  23% /
[root@server ~]# xfs_growfs  /dev/mapper/centos-root
meta-data=/dev/mapper/centos-root isize=512    agcount=4, agsize=877824 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=3511296, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=2560, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 3511296 to 15045632
[root@server ~]# df -h /
Filesystem               Size  Used Avail Use% Mounted on
/dev/mapper/centos-root   58G  3.1G   55G   6% /
[root@server ~]#
```
==== Install XRDP
```bash
sudo yum install -y epel-release
sudo yum install -y xrdp
sudo systemctl start xrdp
sudo systemctl enable xrdp
 
# To confirm the port is listening:
sudo netstat -antup | grep xrdp
```

==== Logs
```bash
# Use journalctl to tail logs, in this case sshd logs
journalctl -u sshd -f
```

==== Manage processes

```bash
# Find PID
ps -ef | grep <pid>

# Kill all firefox processes for all users
kill $(pidof firefox)
```

==== SSH permissions
```bash
+------------------------+-------------------------------------+-------------+-------------+
| Directory or File      | Man Page                            | Recommended | Mandatory   |
|                        |                                     | Permissions | Permissions |
+------------------------+-------------------------------------+-------------+-------------+
| ~/.ssh/                | There is no general requirement to  | 700         |             |
|                        | keep the entire contents of this    |             |             |
|                        | directory secret, but the           |             |             |
|                        | recommended permissions are         |             |             |
|                        | read/write/execute for the user,    |             |             |
|                        | and not accessible by others.       |             |             |
+------------------------+-------------------------------------+-------------+-------------+
| ~/.ssh/authorized_keys | This file is not highly sensitive,  | 600         |             |
|                        | but the recommended permissions are |             |             |
|                        | read/write for the user, and not    |             |             |
|                        | accessible by others                |             |             |
+------------------------+-------------------------------------+-------------+-------------+
| ~/.ssh/config          | Because of the potential for abuse, |             | 600         |
|                        | this file must have strict          |             |             |
|                        | permissions: read/write for the     |             |             |
|                        | user, and not accessible by others. |             |             |
|                        | It may be group-writable provided   |             |             |
|                        | that the group in question contains |             |             |
|                        | only the user.                      |             |             |
+------------------------+-------------------------------------+-------------+-------------+
| ~/.ssh/identity        | These files contain sensitive data  |             | 600         |
| ~/.ssh/id_dsa          | and should be readable by the user  |             |             |
| ~/.ssh/id_rsa          | but not accessible by others        |             |             |
|                        | (read/write/execute)                |             |             |
+------------------------+-------------------------------------+-------------+-------------+
| ~/.ssh/identity.pub    | Contains the public key for         | 644         |             |
| ~/.ssh/id_dsa.pub      | authentication.  These files are    |             |             |
| ~/.ssh/id_rsa.pub      | not sensitive and can (but need     |             |             |
|                        | not) be readable by anyone.         |             |             |
+------------------------+-------------------------------------+-------------+-------------+
```
=== Cloud-init

==== Password hashing
```bash
# mkpasswd can be used to generate a hashed password
sudo apt install whois
mkpasswd --method=SHA-512 --rounds=4096
```
==== Ubuntu
As per https://askubuntu.com/questions/1366315/terraform-cloud-init-via-extra-config-datasourcevmware[this article] on Stack Overflow, edit cloud init's configuration if using "extra config" is desirable with Terraform, rather than vApp settings.

This needs it's own blog post.

1. [Web Browser] Download OVA: https://cloud-images.ubuntu.com/impish/current/impish-server-cloudimg-amd64.ova
2. [VC UI] Deploy from OVF, accept defaults (except disk provisioning, use Thin Provisioning).
3. [VC UI] Edit Settings / VM Options / Boot Options / Boot Delay = 2000ms.
4. [VC UI] Open VM Console.
5. [VM Console] Power On VM.
6. [VM Console] Hold Shift on BIOS screen (to force GRUB to display menu).
7. [VM Console] Select Advanced Options for Ubuntu.
8. [VM Console] Select latest kernel version with "(recovery mode)" at the end.
9. [VM Console] Select "root / Drop to root shell prompt"
10. [VM Console] Press Enter for maintenance
11. [VM Console] # dpkg-reconfigure cloud-init
12. [VM Console] Deselect everything except VMware and None
13. [VM Console] # cloud-init clean
14. [VM Console] # shutdown -h now
15. [VC UI] Edit Settings / VM Options / Boot Options / Boot Delay = 0ms.
16. [VC UI] Convert to template




=== General

==== Proxy
```bash
# Test proxy with WGET (may need a more recent version of WGET)
wget --spider -e use_proxy=yes -e http_proxy=10.61.39.66:80 www.google.com
```

=== Ubuntu

==== Storage performance testing
```bash
# fio https://arstechnica.com/gadgets/2020/02/how-fast-are-your-disks-find-out-the-open-source-way-with-fio/
sudo apt-get install fio

sudo fio --name=random-write --ioengine=posixaio --rw=randrw --bs=4k --numjobs=1 --size=90g --iodepth=1 --runtime=604800 --time_based --end_fsync=1
```

=== Vim

Occasionally I need to paste data in to a file opened with vim and find that it's indenting. Use the the following to control the paste behavour.

```bash
 :set paste
 :set nopaste
 set pastetoggle=<F2> # Allows you to toggle the paste option using the F2 key
```
Great Vim Cheat Sheet: https://vim.rtorr.com/

== Minio

=== Create a policy

I used the following to create a new policy in Minio against server 'test', allowing the user 'user1' to download reports.

```bash

kubectl run -it minio/mc --rm -- bash

# First, create the policy as json with the required configuration allowing read only to the 'reports' url.

cat > policy-name.json << EOF
{
 "Version":"2012-10-17",
 "Statement": [
   {
     "Sid": "AllowUserToSeeBucketListInTheConsole",
     "Action": ["s3:ListAllMyBuckets", "s3:GetBucketLocation"],
     "Effect": "Allow",
     "Resource": ["arn:aws:s3:::reports*"]
   },
   {
     "Sid": "AllowListingOfUserFolder",
     "Action": ["s3:ListBucket"],
     "Effect": "Allow",
     "Resource": ["arn:aws:s3:::reports"]
   },
   {
     "Sid": "AllowAllS3ActionsInUserFolder",
     "Effect": "Allow",
     "Action": ["s3:GetObject"],
     "Resource": ["arn:aws:s3:::reports/*"]
   }
 ]
}
EOF

mc admin policy add test policy-name policy-name.json
mc admin user add test user1 password
mc admin policy set test policy-name user=user1
exit
```

== MySQL

=== Create User
```bash
# Open MySQL database to user1 from all IP's
CREATE USER 'user1'@'%' IDENTIFIED BY 'password';
GRANT ALL PRIVILEGES ON *.* TO 'user1'@'%' IDENTIFIED BY 'password' WITH GRANT OPTION;
FLUSH PRIVILEGES;
BYE;
```
=== Backup Restore
```bash
# Dump specific table from remote host
mysqldump -u root -h <ip> -p <schema> <source_table> > ./backup.sql

# At destination host, restore the table 
mysql -u root -h -p  < ./backup.sql
```
